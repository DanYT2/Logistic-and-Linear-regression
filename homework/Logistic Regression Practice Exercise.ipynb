{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#31394d'> Logistic Regression Practice Exercise </font>\n",
    "\n",
    "For this exercise we are going to use the heart dataset to predict whether or not someone will get a heart attack. You can read more about the dataset here: https://archive.ics.uci.edu/ml/datasets/Heart+Disease). The dataset is provided as a csv file in the `data` folder. \n",
    "\n",
    "ðŸš€ <font color='#d9c4b1'> Exercise: </font> Start by reading in the dataset from the `data` folder and having a look at the data. Don't forget to import the necessary packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   X1  X2  X3   X4   X5  X6  X7   X8  X9  X10  X11  X12      Y\n0  63   1   1  145  233   1   2  150   0  2.3    3  0.0  False\n1  67   1   4  160  286   0   2  108   1  1.5    2  3.0   True\n2  67   1   4  120  229   0   2  129   1  2.6    2  2.0   True\n3  37   1   3  130  250   0   0  187   0  3.5    3  0.0  False\n4  41   0   2  130  204   0   2  172   0  1.4    1  0.0  False",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X1</th>\n      <th>X2</th>\n      <th>X3</th>\n      <th>X4</th>\n      <th>X5</th>\n      <th>X6</th>\n      <th>X7</th>\n      <th>X8</th>\n      <th>X9</th>\n      <th>X10</th>\n      <th>X11</th>\n      <th>X12</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>1</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>2</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67</td>\n      <td>1</td>\n      <td>4</td>\n      <td>160</td>\n      <td>286</td>\n      <td>0</td>\n      <td>2</td>\n      <td>108</td>\n      <td>1</td>\n      <td>1.5</td>\n      <td>2</td>\n      <td>3.0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67</td>\n      <td>1</td>\n      <td>4</td>\n      <td>120</td>\n      <td>229</td>\n      <td>0</td>\n      <td>2</td>\n      <td>129</td>\n      <td>1</td>\n      <td>2.6</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37</td>\n      <td>1</td>\n      <td>3</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>0</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41</td>\n      <td>0</td>\n      <td>2</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>2</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here!\n",
    "# Hint: df = pd.read_csv('data/...')\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ <font color='#d9c4b1'> Exercise: </font> Now standardize the features. You can learn more about standardization in the `Logistic Regression.ipynb` notebook that we used during the session!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         X1        X2        X3        X4        X5        X6        X7  \\\n0  0.940674  0.692963 -2.247558  0.754191 -0.272061  2.407375  1.010130   \n1  1.384830  0.692963  0.873277  1.602797  0.750555 -0.415390  1.010130   \n2  1.384830  0.692963  0.873277 -0.660154 -0.349239 -0.415390  1.010130   \n3 -1.946337  0.692963 -0.167001 -0.094416  0.055948 -0.415390 -1.003395   \n4 -1.502182 -1.443078 -1.207280 -0.094416 -0.831605 -0.415390  1.010130   \n\n         X8        X9       X10       X11       X12  \n0  0.021599 -0.698257  1.074277  2.267657 -0.718306  \n1 -1.811141  1.432138  0.385726  0.645577  2.487269  \n2 -0.894771  1.432138  1.332483  0.645577  1.418744  \n3  1.636156 -0.698257  2.107102  2.267657 -0.718306  \n4  0.981606 -0.698257  0.299658 -0.976503 -0.718306  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X1</th>\n      <th>X2</th>\n      <th>X3</th>\n      <th>X4</th>\n      <th>X5</th>\n      <th>X6</th>\n      <th>X7</th>\n      <th>X8</th>\n      <th>X9</th>\n      <th>X10</th>\n      <th>X11</th>\n      <th>X12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.940674</td>\n      <td>0.692963</td>\n      <td>-2.247558</td>\n      <td>0.754191</td>\n      <td>-0.272061</td>\n      <td>2.407375</td>\n      <td>1.010130</td>\n      <td>0.021599</td>\n      <td>-0.698257</td>\n      <td>1.074277</td>\n      <td>2.267657</td>\n      <td>-0.718306</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.384830</td>\n      <td>0.692963</td>\n      <td>0.873277</td>\n      <td>1.602797</td>\n      <td>0.750555</td>\n      <td>-0.415390</td>\n      <td>1.010130</td>\n      <td>-1.811141</td>\n      <td>1.432138</td>\n      <td>0.385726</td>\n      <td>0.645577</td>\n      <td>2.487269</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.384830</td>\n      <td>0.692963</td>\n      <td>0.873277</td>\n      <td>-0.660154</td>\n      <td>-0.349239</td>\n      <td>-0.415390</td>\n      <td>1.010130</td>\n      <td>-0.894771</td>\n      <td>1.432138</td>\n      <td>1.332483</td>\n      <td>0.645577</td>\n      <td>1.418744</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.946337</td>\n      <td>0.692963</td>\n      <td>-0.167001</td>\n      <td>-0.094416</td>\n      <td>0.055948</td>\n      <td>-0.415390</td>\n      <td>-1.003395</td>\n      <td>1.636156</td>\n      <td>-0.698257</td>\n      <td>2.107102</td>\n      <td>2.267657</td>\n      <td>-0.718306</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.502182</td>\n      <td>-1.443078</td>\n      <td>-1.207280</td>\n      <td>-0.094416</td>\n      <td>-0.831605</td>\n      <td>-0.415390</td>\n      <td>1.010130</td>\n      <td>0.981606</td>\n      <td>-0.698257</td>\n      <td>0.299658</td>\n      <td>-0.976503</td>\n      <td>-0.718306</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here!\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df.drop('Y', axis=1))\n",
    "scaled_features = scaler.transform(df.drop('Y', axis=1))\n",
    "df_feat = pd.DataFrame(scaled_features, columns=df.columns[:-1])\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ <font color='#d9c4b1'> Exercise: </font> Fit a standard logistic regression model and determine which features look most promising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.06123998,  0.85211752,  0.64011653,  0.435613  ,  0.2842153 ,\n        -0.29379629,  0.16021018, -0.48903304,  0.5175928 ,  0.31992612,\n         0.41258919,  1.11113907]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here!\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(df_feat, df['Y'])\n",
    "logmodel.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The most promising features are X1, X2, X11, X8, X3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ <font color='#d9c4b1'> Exercise: </font> Fit another model that includes only the features that you think look promising. Use cross validation and the accuracy, precision, and recall scoring metrics to determine which model is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75       0.86666667 0.7        0.81666667 0.76271186]\n",
      "0.7792090395480225\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here!\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "logmodel = LogisticRegression()\n",
    "\n",
    "important_features= df_feat[['X1', 'X2', 'X11', 'X8', 'X3']]\n",
    "logmodel.fit(important_features, df['Y'])\n",
    "scores = cross_val_score(logmodel, important_features, df['Y'], cv=5)\n",
    "print(scores)\n",
    "print(scores.mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
